# Pretext Learning
* [2016] [Shuffle and Learn: Unsupervised Learning Using Temporal Order Verification](https://link.springer.com/chapter/10.1007/978-3-319-46448-0_32)
* [2017] [Unsupervised Representation Learning by Sorting Sequences](https://openaccess.thecvf.com/content_ICCV_2017/papers/Lee_Unsupervised_Representation_Learning_ICCV_2017_paper.pdf)
* [2017] [Self-Supervised Video Representation Learning With Odd-One-Out Networks](https://openaccess.thecvf.com/content_cvpr_2017/papers/Fernando_Self-Supervised_Video_Representation_CVPR_2017_paper.pdf)
* [2018] [Geometry guided convolutional neural networks for self-supervised video representation learning](https://ieeexplore.ieee.org/document/8578684).
* [2019] [Self-Supervised Spatiotemporal Learning via Video Clip Order Prediction](https://ieeexplore.ieee.org/document/8953292)
* [2019] [Self-Supervised Spatio-Temporal Representation Learning for Videos by Predicting Motion and Appearance Statistics](https://arxiv.org/abs/1904.03597)
* [2019] [Self-Supervised Spatiotemporal Feature Learning via Video Rotation Prediction](https://openaccess.thecvf.com/content_CVPR_2019/papers/Xu_Self-Supervised_Spatiotemporal_Learning_via_Video_Clip_Order_Prediction_CVPR_2019_paper.pdf)
* [2019] [Video jigsaw: Unsupervised learning of spatiotemporal context for video action recognition](https://ieeexplore.ieee.org/document/8659002)
* [2019] [Self-supervised video representation learning with space-time cubic puzzles](https://dl.acm.org/doi/10.1609/aaai.v33i01.33018545)
* [2020] [Video representation learning by recognizing temporal transformations](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123730426.pdf)
* [2020] [Memory-Augmented Dense Predictive Coding for Video Representation Learning](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123480324.pdf)
* [2020] [Video Playback Rate Perception for Self-Supervised Spatio-Temporal Representation Learning](https://openaccess.thecvf.com/content_CVPR_2020/papers/Yao_Video_Playback_Rate_Perception_for_Self-Supervised_Spatio-Temporal_Representation_Learning_CVPR_2020_paper.pdf)
* [2020] [SpeedNet: Learning the Speediness in Videos](https://openaccess.thecvf.com/content_CVPR_2020/papers/Benaim_SpeedNet_Learning_the_Speediness_in_Videos_CVPR_2020_paper.pdf)
* [2020] [Video representation learning by recognizing temporal transformations](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123730426.pdf)
* [2020] [Self-supervised Video Representation Learning by Pace Prediction](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123620494.pdf)
* [2020] [Self-Supervised video representation using pretext-contrastive learning](https://arxiv.org/abs/2010.15464)
* [2020] [Labelling unlabelled videos from scratch with multi-modal self-supervision](https://arxiv.org/pdf/2006.13662.pdf)
* [2020] [Self-supervised co-training for video representation learning](https://proceedings.neurips.cc/paper/2020/file/3def184ad8f4755ff269862ea77393dd-Paper.pdf)
* [2020] [Multi-modal Self-Supervision from Generalized Data Transformations](https://arxiv.org/abs/2003.04298)
* [2021] [Self-Supervised Video Representation Learning with Constrained Spatiotemporal Jigsaw](https://www.ijcai.org/proceedings/2021/104)
* [2021] [Enhancing unsupervised video representation learning by decoupling the scene and the motion](https://arxiv.org/abs/2009.05757)

# Generative Learning
* [2016] [Deep multi-scale video prediction beyond mean square error](https://arxiv.org/abs/1511.05440)
* [2016] [Generating videos with scene dynamics](https://dl.acm.org/doi/pdf/10.5555/3157096.3157165)
* [2017] [Dual Motion GAN for Future-Flow Embedded Video Prediction](https://openaccess.thecvf.com/content_ICCV_2017/papers/Liang_Dual_Motion_GAN_ICCV_2017_paper.pdf)
* [2019] [Learning Video Representations using Contrastive Bidirectional Transformer](https://arxiv.org/abs/1906.05743)
* [2019] [VideoBERT: A joint model for video and language representation learning](https://openaccess.thecvf.com/content_ICCV_2019/papers/Sun_VideoBERT_A_Joint_Model_for_Video_and_Language_Representation_Learning_ICCV_2019_paper.pdf)
* [2020] [Self-supervised motion representation via scattering local motion cues](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123590069.pdf)
* [2020] [UniVL: A unified video and language pre-training model for multimodal understanding and generation](https://arxiv.org/abs/2002.06353)
* [2020] [HERO: Hierarchical Encoder for Video+ Language Omni-representation Pre-training](https://aclanthology.org/2020.emnlp-main.161/)
* [2021] [Less is more: Clipbert for video-and-language learning via sparse sampling](https://openaccess.thecvf.com/content/CVPR2021/papers/Lei_Less_Is_More_ClipBERT_for_Video-and-Language_Learning_via_Sparse_Sampling_CVPR_2021_paper.pdf)
* [2021] [A Large-Scale Study on Unsupervised Spatiotemporal Representation Learning](https://openaccess.thecvf.com/content/CVPR2021/papers/Feichtenhofer_A_Large-Scale_Study_on_Unsupervised_Spatiotemporal_Representation_Learning_CVPR_2021_paper.pdf)
* [2021] [Videomoco: Contrastive video representation learning with temporally adversarial examples](https://openaccess.thecvf.com/content/CVPR2021/papers/Pan_VideoMoCo_Contrastive_Video_Representation_Learning_With_Temporally_Adversarial_Examples_CVPR_2021_paper.pdf)
* [2021] [VLM: Task-agnostic Video-Language Model Pre-training for Video Understanding](https://aclanthology.org/2021.findings-acl.370/)
* [2022] [bevt: Bert pretraining of video transformers](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_BEVT_BERT_Pretraining_of_Video_Transformers_CVPR_2022_paper.pdf)
* [2022] [Masked Autoencoders As Spatiotemporal Learners](https://arxiv.org/abs/2205.09113)
* [2022] [Masked Feature Prediction for Self-Supervised Visual Pre-Training](https://openaccess.thecvf.com/content/CVPR2022/papers/Wei_Masked_Feature_Prediction_for_Self-Supervised_Visual_Pre-Training_CVPR_2022_paper.pdf)
* [2022] [Video{MAE}: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training](https://arxiv.org/abs/2203.12602)
* [2022] [Self-supervised Video Representation Learning with Motion-Aware Masked Autoencoders](https://arxiv.org/abs/2210.04154)

# Cross-Modal Learning
* [2018] [Learning a text-video embedding from incomplete and heterogeneous data](https://arxiv.org/abs/1804.02516)
* [2019] [Learning Video Representations using Contrastive Bidirectional Transformer](https://arxiv.org/abs/1906.05743)
* [2019] [VideoBERT: A joint model for video and language representation learning](https://openaccess.thecvf.com/content_ICCV_2019/papers/Sun_VideoBERT_A_Joint_Model_for_Video_and_Language_Representation_Learning_ICCV_2019_paper.pdf)
* [2019] [Use What You Have: Video retrieval using representations from collaborative experts](https://arxiv.org/abs/1907.13487)
* [2019] [Fine-grained action retrieval through multiple parts-of-speech embeddings](https://openaccess.thecvf.com/content_ICCV_2019/papers/Wray_Fine-Grained_Action_Retrieval_Through_Multiple_Parts-of-Speech_Embeddings_ICCV_2019_paper.pdf)
* [2020] [End-to-end learning of visual representations from uncurated instructional videos](https://openaccess.thecvf.com/content_CVPR_2020/papers/Miech_End-to-End_Learning_of_Visual_Representations_From_Uncurated_Instructional_Videos_CVPR_2020_paper.pdf)
* [2020] [COOT: Cooperative hierarchical transformer for video-text representation learning](https://dl.acm.org/doi/10.5555/3495724.3497619)
* [2020] [ActBERT: Learning global-local video-text representations](https://openaccess.thecvf.com/content_CVPR_2020/papers/Zhu_ActBERT_Learning_Global-Local_Video-Text_Representations_CVPR_2020_paper.pdf)
* [2020] [UniVL: A unified video and language pre-training model for multimodal understanding and generation](https://arxiv.org/abs/2002.06353)
* [2020] [AVLnet: Learning Audio-Visual Language Representations from Instructional Videos](https://arxiv.org/abs/2006.09199)
* [2020] [HERO: Hierarchical Encoder for Video+ Language Omni-representation Pre-training](https://aclanthology.org/2020.emnlp-main.161/)
* [2020] [Multi-modal transformer for video retrieval](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123490205.pdf)
* [2020] [Support-set bottlenecks for video-text representation learning](https://arxiv.org/abs/2010.02824)
* [2021] [A Joint Video and Image Encoder for End-to-End Retrieval](https://arxiv.org/abs/2104.00650)
* [2021] [Less is more: Clipbert for video-and-language learning via sparse sampling](https://openaccess.thecvf.com/content/CVPR2021/papers/Lei_Less_Is_More_ClipBERT_for_Video-and-Language_Learning_via_Sparse_Sampling_CVPR_2021_paper.pdf)
* [2021] [VLM: Task-agnostic Video-Language Model Pre-training for Video Understanding](https://aclanthology.org/2021.findings-acl.370/)
* [2021] [VideoCLIP: Contrastive pre-training for zero-shot video-text understanding](https://aclanthology.org/2021.emnlp-main.544/)
* [2021] [Noise estimation using density estimation for self-supervised multimodal learning](https://arxiv.org/abs/2003.03186)
* [2021] [VATT: Transformers for multimodal self-supervised learning from raw video, audio and text](https://arxiv.org/abs/2104.11178)
